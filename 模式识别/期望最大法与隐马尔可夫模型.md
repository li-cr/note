# EM算法

## 算法介绍
- EM是一类通过迭代实现参数估计的优化算法
	- 作为最大似然法的替代，用于对包含隐变量或缺失数据的概率模型进行参数估计
- EM算法解决的问题：包含隐变量的概率密度参数估计
	- 观测变量：x；隐含变量：z
	- 任务：给定数据集X={$\,x_1,x_2,\dots,x_n\,$}，估计观测数据概率密度的参数。
- EM算法的基本要素
	- 观测数据：$X={\,x_1,x_2,\dots,x_n\,}$（不完全数据）
	- 隐含数据：$Z={\,z_1,z_2,\dots,z_n|,}$
	- 观测数据的概率密度函数：$p(x|\theta)$
	- 完全数据的联合概率密度函数：$p(x,z|\theta)$
	- 观测数据的对数似然函数：$\ln\prod\limits_{i=1}^np(x_i|\theta)=\sum\limits_{i=1}^n\ln p(x_i|\theta)$
	- 完全数据的对数似然函数：$\ln\prod\limits_{i=1}^np(x_i,z_i|\theta)=\sum\limits_{i=1}^n\ln p(x_i,z_i|\theta)$
- EM算法步骤
	- 初始化$\,\theta^{\,old}$
	- Repeat
		- E step: $基于当前\,\theta^{\,old}和样本，估计隐变两的后验分布\,p(z_i\,|\,x_i,\theta^{\,old})，并计算Q(\theta,\theta^{old}):$
			- $\begin{aligned} \large Q(\theta,\theta^{old})&=\sum\limits_{i}E_{p(z_i|x_i,\theta^{old})}[\ln(p(x_i,z_i|\theta)))] \quad \{对ln求期望，不是两者相乘！！！\}\\ &=\sum\limits_{i}\sum\limits_{z_i}p(z_i|x_i,\theta^{odd})\ln(p(x_i,z_i|\theta)\end{aligned}$
		- M step: $更新参数\theta$：
			- $\theta^{new}=\rm{arg \;\underset{\theta}{min}}\; Q(\theta,\theta^{odd})\quad\{这里表明了只是估计概率密度函数的参数，隐变量的类别似乎是按照概率来分配的？\}$
## EM for Gaussian mixture model
