# 最大似然和贝叶斯参数估计

## <span style="color:#6980f2">基本概念</span>

- $\large{贝叶斯分类器}$
	- 已知类先验概率$P(\omega_i)$和类条件概率密度$\,p(x|\omega_i)\,$，按<span style="color:#ff4f90">某决策规则</span>确定判别函数和决策面。
	- 但<span style="color:#afff7f">类先验概率密度</span>和<span style="color:#00cf00">类条件概率密度</span>在<span style="color:#ff4f90">实际中往往是未知的</span>。
	- 因此，我们要换一种处理问题的方式：“<font color="#00aaff">从样本出发来设计分类器</font>"。根据设计方法，可以将分类器分为两类：
		- 估计<font color="#c0aaff">类先验概率密度和类条件概率密度函数</font>（产生式方法）
		- 直接估计<font color="#c0aaff">类后验概率或判别函数</font>（判别式方法）
- $\large{方法分类}$
	- 参数估计：
		- 样本所属的类条件概率密度函数的<font color="#ff60">形式已知</font>，而概率密度函数的<font color="#ff60">参数是未知</font>的。
		- 目标是由已知类别的样本集估计概率密度函数的参数。
		- 例如，知道样本所属总体为正态分布，而正态分布的参数未知
		  $$p(x\,|\,\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}\exp\Big(-\frac{1}{2}\big(\frac{x-\mu}{\sigma} \big)^2 \Big)$$
	- 非参数估计：
		- 样本所属的类条件概率密度函数的<font color="#ff60">形式和参数都是未知的</font>，目标是由已知类别的样本集估计类条件概率密度函数本身。
- $统计量：样本中包含总体的信息，我们希望通过样本集将有关信息估计出来。根据不同要求构造出有关样本的某种函数，在统计学中成为统计量\;d(x_1,x_2,\dots,x_n)$
	- 比如：均值$\quad \mu=\frac{1}{n}\sum\limits_{i=1}^{n}x_i$
- $参数空间：将位置待估计的参数记为\,\theta，参数\theta的\pmb{全部允许取值集合}构成参数空间，记为\Theta。$
	- $点估计：点估计问题就是构造一个统计量\,d(x_1,x_2,\dots,x_n)作为参数\theta的估计\hat{\theta}。比如，常用的均值估计：$
	  $$\hat\mu=\frac{1}{n}\sum\limits_{i=1}^{n}x_i$$
	- $区间估计：与点估计不同，区间估计要求采用\,(d_1,d_2)\,作为参数\,\theta\,可能取值范围的一种估计。这个区间称为\pmb{置信区间}。这类估计问题称为\pmb{区间估计}。$
- $\large{基本假设}$
	- <font color="#da0101">独立同分布假设</font>：每类样本均是从类条件概率密度$p(x|\omega_i)$中<font color="#00a0ff">独立抽取</font>出来的。
	- $p(x|\omega_i)$具有确定的函数形式，只是其中的参数$\,\theta\,$未知：
		- 比如当$\,x\,$服从一维正态分布$\,N(\mu,\sigma^2)\,$，未知的参数为$\,\theta=[\mu,\sigma]^T$,是一个二维向量。
	- <font color="#da0101">各类样本只包含本类的分布信息</font>：<font color="#00a0ff">即不同类别的参数是独立的</font>。可以分别处理c个独立问题。
## 最大似然估计

- 基本假设
	- **独立同分布假设**：每类样本均是从类条件概率密度$p(x|\omega_i)$中独立抽取出来的。
	- $p(x|\omega_i)$具有确定的函数形式，只是其中的参数$\theta$未知：
		- 比如，当x服从一维正态分布$N(\mu,\sigma^2)$，具体的参数为$\theta=[\mu,\sigma]^T$，是一个二维向量。
	- **各类样本只包含本类的分布信息**：即不同类被的参数是独立的。可以分别处理c个独立问题。
- 基本原理
	- 已知随机抽取的n个样本（观测值），最合理的参数估计应该是使得从该模型中能抽取这n个样本的概率最大。
	- 设样本集包含n个样$D=\{x_1,x_2,\dots,x_n\}$，这些样本是从该概率密度函数$p(x|\theta)$中独立抽取的，则获得n个样本的联合概率为：$$l(\theta)=P(D|\theta)=p(x_1,x_2,\dots,x_n|\theta)=\prod_{i=1}^{n}p(x_i|\theta)$$
	- $\displaystyle\frac{\partial tr(A\Sigma^{-1}B)}{\partial \Sigma}=(-\Sigma^{-1}BA\Sigma^{-1})^T\implies\frac{\partial x^T\Sigma^{-1}x}{\partial\Sigma}=-\Sigma^{-1}xx^T\Sigma^{-1}$
	- $\displaystyle\frac{\partial |\Sigma|}{\partial \Sigma}=|\Sigma|(\Sigma^{-1})$
		- $\displaystyle\frac{\partial H(\mu)}{\partial \mu}=\sum\limits_{i=1}^{n}{\frac{\partial \ln p(x_i|\mu,\Sigma)}{\partial \mu}} = \sum\limits_{i=1}^{n}\Sigma^{-1}(x_i-\mu)$
		- $\displaystyle\frac{\partial H(\Sigma)}{\partial \Sigma}=\sum\limits_{i=1}^{n}{\frac{\partial \ln p(x_i|\mu,\Sigma)}{\partial \Sigma}} = \sum\limits_{i=1}^{n}\Big(-\frac{1}{2}\Sigma^{-1}-\frac{1}{2}(-\Sigma^{-1}(x_i-\mu)(x_i-\mu)^T\Sigma^{-1})\Big)$
		- 推出$\displaystyle\;\hat{\mu}=\frac{1}{n}\sum\limits_{i=1}^{n}x_i, \quad\hat{\Sigma}=\frac{1}{n}\sum\limits_{i=1}^{n}(x_i-\hat{\mu})(x_i-\hat{\mu})^T$

## 贝叶斯估计

- 贝叶斯估计与最大似然估计
	- 贝叶斯估计在很多情况下与最大似然法十分相似，但是，两种方法对问题的处理视角是一样的。
		- 最大似然估计是将待估计的参数当<font color="#a0ffff">未知但固定的变量</font>，其任务是根据观测数据估计其在参数空间的取值。
		- 贝叶斯估计是将待估计的参数<font color="#60ffff">视为一个随机变量</font>，其中的一个核心任务是根据观测数据<font color="#aff0ff">对参数的分布进行估计</font>

### 基本方法

- 参数先验分布$\,p(\theta)\,$：是指在没有任何数据时，有关参数$\,\theta\,$的分布情况，（根据领域知识或经验）
- 给定样本集$\quad D=\{x_1,x_2,\dots,x_n\}$，数据独立采样，且服从数据分布：
	- $p(D|\,\theta\,)=p(x_1,x_2,\dots,x_n|\,\theta\,)=\prod_\limits{i=1}^{n}p(x_i|\theta)$
	- $p(D_i|\,\theta\,)=p(x_1,x_2,\dots,x_i|\,\theta\,)=p(D_{i-1}|\,\theta\,)\,p(x_i|\,\theta\,)$
	- 利用贝叶斯公式估计参数的后验分布$p(\theta|D)$：
		- $\displaystyle p(\theta|D)=\frac{p(D|\theta)\,p(\theta)}{p(D)}$