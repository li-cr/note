# 最大似然和贝叶斯参数估计

## <span style="color:#6980f2">基本概念</span>

- $\large{贝叶斯分类器}$
	- 已知类先验概率$P(\omega_i)$和类条件概率密度$\,p(x|\omega_i)\,$，按<span style="color:#ff4f90">某决策规则</span>确定判别函数和决策面。
	- 但<span style="color:#afff7f">类先验概率密度</span>和<span style="color:#00cf00">类条件概率密度</span>在<span style="color:#ff4f90">实际中往往是未知的</span>。
	- 因此，我们要换一种处理问题的方式：“<font color="#00aaff">从样本出发来设计分类器</font>"。根据设计方法，可以将分类器分为两类：
		- 估计<font color="#c0aaff">类先验概率密度和类条件概率密度函数</font>（产生式方法）
		- 直接估计<font color="#c0aaff">类后验概率或判别函数</font>（判别式方法）
- $\large{方法分类}$
	- 参数估计：
		- 样本所属的类条件概率密度函数的<font color="#ff60">形式已知</font>，而概率密度函数的<font color="#ff60">参数是未知</font>的。
		- 目标是由已知类别的样本集估计概率密度函数的参数。
		- 例如，知道样本所属总体为正态分布，而正态分布的参数未知
		  $$p(x\,|\,\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}\exp\Big(-\frac{1}{2}\big(\frac{x-\mu}{\sigma} \big)^2 \Big)$$
	- 非参数估计：
		- 样本所属的类条件概率密度函数的<font color="#ff60">形式和参数都是未知的</font>，目标是由已知类别的样本集估计类条件概率密度函数本身。
- $统计量：样本中包含总体的信息，我们希望通过样本集将有关信息估计出来。根据不同要求构造出有关样本的某种函数，在统计学中成为统计量\;d(x_1,x_2,\dots,x_n)$
	- 比如：均值$\quad \mu=\frac{1}{n}\sum\limits_{i=1}^{n}x_i$
- $参数空间：将位置待估计的参数记为\,\theta，参数\theta的\pmb{全部允许取值集合}构成参数空间，记为\Theta。$
	- $点估计：点估计问题就是构造一个统计量\,d(x_1,x_2,\dots,x_n)作为参数\theta的估计\hat{\theta}。比如，常用的均值估计：$
	  $$\hat\mu=\frac{1}{n}\sum\limits_{i=1}^{n}x_i$$
	- $区间估计：与点估计不同，区间估计要求采用\,(d_1,d_2)\,作为参数\,\theta\,可能取值范围的一种估计。这个区间称为\pmb{置信区间}。这类估计问题称为\pmb{区间估计}。$
- $\large{基本假设}$
	- <font color="#da0101">独立同分布假设</font>：每类样本均是从类条件概率密度$p(x|\omega_i)$中<font color="#00a0ff">独立抽取</font>出来的。
	- $p(x|\omega_i)$具有确定的函数形式，只是其中的参数$\,\theta\,$未知：
		- 比如当$\,x\,$服从一维正态分布$\,N(\mu,\sigma^2)\,$，未知的参数为$\,\theta=[\mu,\sigma]^T$,是一个二维向量。
	- <font color="#da0101">各类样本只包含本类的分布信息</font>：<font color="#00a0ff">即不同类别的参数是独立的</font>。可以分别处理c个独立问题。
## 最大似然估计

- 基本假设
	- **独立同分布假设**：每类样本均是从类条件概率密度$p(x|\omega_i)$中独立抽取出来的。
	- $p(x|\omega_i)$具有确定的函数形式，只是其中的参数$\theta$未知：
		- 比如，当x服从一维正态分布$N(\mu,\sigma^2)$，具体的参数为$\theta=[\mu,\sigma]^T$，是一个二维向量。
	- **各类样本只包含本类的分布信息**：即不同类被的参数是独立的。可以分别处理c个独立问题。
- 基本原理
	- 已知随机抽取的n个样本（观测值），最合理的参数估计应该是使得从该模型中能抽取这n个样本的概率最大。
	- 设样本集包含n个样$D=\{x_1,x_2,\dots,x_n\}$，这些样本是从该概率密度函数$p(x|\theta)$中独立抽取的，则获得n个样本的联合概率为：$$l(\theta)=P(D|\theta)=p(x_1,x_2,\dots,x_n|\theta)=\prod_{i=1}^{n}p(x_i|\theta)$$
	- $\displaystyle\frac{\partial tr(A\Sigma^{-1}B)}{\partial \Sigma}=(-\Sigma^{-1}BA\Sigma^{-1})^T\implies\frac{\partial x^T\Sigma^{-1}x}{\partial\Sigma}=-\Sigma^{-1}xx^T\Sigma^{-1}$
	- $\displaystyle\frac{\partial |\Sigma|}{\partial \Sigma}=|\Sigma|(\Sigma^{-1})$
		- $\displaystyle\frac{\partial H(\mu)}{\partial \mu}=\sum\limits_{i=1}^{n}{\frac{\partial \ln p(x_i|\mu,\Sigma)}{\partial \mu}} = \sum\limits_{i=1}^{n}\Sigma^{-1}(x_i-\mu)$
		- $\displaystyle\frac{\partial H(\Sigma)}{\partial \Sigma}=\sum\limits_{i=1}^{n}{\frac{\partial \ln p(x_i|\mu,\Sigma)}{\partial \Sigma}} = \sum\limits_{i=1}^{n}\Big(-\frac{1}{2}\Sigma^{-1}-\frac{1}{2}(-\Sigma^{-1}(x_i-\mu)(x_i-\mu)^T\Sigma^{-1})\Big)$
		- 推出$\displaystyle\;\hat{\mu}=\frac{1}{n}\sum\limits_{i=1}^{n}x_i, \quad\hat{\Sigma}=\frac{1}{n}\sum\limits_{i=1}^{n}(x_i-\hat{\mu})(x_i-\hat{\mu})^T$

## 贝叶斯估计

- 贝叶斯估计与最大似然估计
	- 贝叶斯估计在很多情况下与最大似然法十分相似，但是，两种方法对问题的处理视角是一样的。
		- 最大似然估计是将待估计的参数当<font color="#a0ffff">未知但固定的变量</font>，其任务是根据观测数据估计其在参数空间的取值。
		- 贝叶斯估计是将待估计的参数<font color="#60ffff">视为一个随机变量</font>，其中的一个核心任务是根据观测数据<font color="#aff0ff">对参数的分布进行估计</font>

### 基本方法

- 参数先验分布$\,p(\theta)\,$：是指在没有任何数据时，有关参数$\,\theta\,$的分布情况，（根据领域知识或经验）
- 给定样本集$\quad D=\{x_1,x_2,\dots,x_n\}$，数据独立采样，且服从数据分布：
	- $p(D|\,\theta\,)=p(x_1,x_2,\dots,x_n|\,\theta\,)=\prod_\limits{i=1}^{n}p(x_i|\theta)$
	- $p(D_i|\,\theta\,)=p(x_1,x_2,\dots,x_i|\,\theta\,)=p(D_{i-1}|\,\theta\,)\,p(x_i|\,\theta\,)$
	- 利用贝叶斯公式估计参数的后验分布$p(\theta|D)$：
		- $\displaystyle p(\theta|D)=\frac{p(D|\theta)\,p(\theta)}{p(D)}$
		- $p(\theta|D) 中融合了先验知识和数据信息$
- $P(D)是与参数无关的归一化因子，根据全概率公式:p(D=\sum\limits_{i}p(D|\theta_i)p(\theta_i)$
	- $\displaystyle p(D) = \int_{\theta}p(D|\theta)p(\theta)d\theta$
	- 可得到贝叶斯参数估计的<font color="#00ffff">后验概率密度函数</font>：

 	> - $\huge p(\theta|D) =\frac{p(D|\theta)p(\theta)}{\int_{\theta}p(D|\theta)p(\theta)d\theta}=\frac{\prod\limits_{i=1}^n{p(x_i|\theta)p(\theta)}}{\int_\theta\prod\limits_{i=1}^{n}{p(x_i|\theta)}p(\theta)d\theta} = \alpha\prod\limits_{i=1}^np(x_i|\theta)p(\theta)$
 - **$如何使用p(\theta|D)获得关于数据的分布\,?$**
	 - 得到$p(\theta|D)$只是获取了关于参数$\,\theta\,$的后验分布，并没有像最大似然估计那样获得参数$\,\theta\,$的具体取值。
	 - <font color="#ff00ff">方法一</font>：可对$p(\theta|D)采样，计算平均值$
		 - $\displaystyle\hat{\theta}=\frac{1}{M}\sum\limits_{i=1}^M\theta_i\quad \quad \theta_i\sim p(\theta|D)\quad \quad i=1,\dots,M$
	 - <font color="#ff00ff">方法二</font>：最大后验估计(Maximum A Posteriori estimation, MAP)
		 - $\quad\quad\quad\quad\quad\qquad\quad
		   \begin{aligned}
		   \hat{\theta} &={\rm{arg\;max\;}}p(\theta|D) \\  \Longleftrightarrow\hat{\theta} &= {\rm{arg\;max\;}}p(D|\theta)p(\theta) \\\Longleftrightarrow\hat{\theta} &= {\rm{arg\;max\;}}\ln p(D|\theta)+\ln p(\theta) \end{aligned}$
		- PR/ML 方法中普遍使用的L2正则，等价于假设参数服从$N(0, I)$
- <font color="#ff30">方法三</font>：后验数据分布（完整的贝叶斯方法）
	- 我们的最终目的是根据D中的样本来估计概率密度函数$p(x|D)$。
		- 比如，假定观测样本服从正态分布$p(x|\mu,\Sigma)$，给定D，可以估计得到具体的<font color="#ff00ff">$\,\mu\,$和$\,\Sigma\,$</font>的取值，代入如下公式可以得到关于样本的密度分布函数：
			- $\displaystyle p(x|\mu,\Sigma)=\frac{1}{(2\pi)^{d/2}{|\Sigma|}^\frac{1}{2}}\exp\Big(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\Big)$
- <font color="#ff30">后验数据分布</font>
	- 但现在获得了有关$\theta$的后验估计$p(\theta|D)，如何估计p(x|D)？$考虑<font color="#a0ffff">全概率公式和边际分布：</font>
		- $\begin{aligned}p(x|D)&=\int_\theta p(x,\theta|D)d\theta\\&=\int_\theta\frac{p(x,\theta,D)}{p(D)}d\theta\\ &=\int_\theta\frac{p(x|\theta,D)p(\theta,D)}{p(D)}d\theta \\&=\int_\theta p(x|\theta,D)p(\theta|D)d\theta\\ &=\int_\theta p(x|\theta)p(\theta|D) \quad[给定参数\theta时，样本分布与训练集D无关，P(\theta|D)=不同参数的密度函数的加权平均]\end{aligned}$
		- 积分通常很难计算，使用近似方法：
			- $\hat{p}(x|D)=\frac{1}{M}\sum\limits_{i=1}^Mp(x|\theta_i)\quad\theta_i\sim p(\theta|D)\quad i=1,\dots,M$
				- M个不同参数的密度函数的平均
### 正态分布下的贝叶斯参数估计
- 假定一维情况下，$x\sim N(\mu,\sigma^2)$且仅$\mu$未知。
- 假定参数$\,\mu\,$的先验概率也服从正态分布
	- $\quad\mu\sim N(\mu_0,\sigma_0^2)$
- 首先：在给定样本集D的情况下，估计关于参数的后验分布$\,p(\mu|D)\,$。
	- $p(x|\mu)=N(\mu,\sigma^2),\;p(\mu)=N(\mu_0,\sigma_0^2), \quad$<font color="#ffa0">$\Huge\sigma,\mu_0,\sigma_0已知$</font>
	- $\large\begin{aligned} p(\mu|D) &=\alpha\prod\limits_{i=1}^np(x_i|\mu)p(\mu) \\ &=\alpha\prod\limits_{i=1}^{n} A\exp\Big(-\frac{1}{2}\frac{(x_i-\mu)^2}{\sigma^2}\Big)B\exp\Big(-\frac{1}{2}\frac{(\mu-\mu_0)^2}{\sigma_0^2}\Big)\\ &=\alpha^{'}\exp\Bigg\{-\frac{1}{2}\Bigg(\sum\limits_{i=1}^{n}\Big(\frac{(x_i-\mu)^2}{\sigma^2}\Big)+\frac{(\mu-\mu_0)^2}{\sigma_0^2} \Bigg) \Bigg\} \\ p(\mu|D)&=\alpha^{''}\exp\Bigg(-\frac{1}{2}\Bigg(\Big(\frac{n}{\sigma^2}+\frac{1}{\sigma_0^2}\Big)\mu^2-2\Big(\frac{1}{\sigma^2}\sum\limits_{i=1}^{n}x_i+\frac{\mu_0}{\sigma_0^2} \Big)\mu\Bigg) \Bigg)\end{aligned}$
	- $p(\mu|D)$是关于$\mu$的的exp二次函数，因此，其是正态分布密度函数。也被称为reproducing density，由于对于任意数量的训练样本，其随着样本数的增加仍然保持正态分布。
	- $\displaystyle p(\mu|D)\sim N(\mu_n,\sigma_n^2)=\frac{1}{\sqrt{2\pi\sigma_n}}\exp\Bigg(-\frac{1}{2}\frac{(\mu-\mu_n)^2}{\sigma_n^2}\Bigg)$
	     >  $\Huge\begin{aligned}\frac{1}{\sigma_n^2}=\frac{n}{\sigma^2}+\frac{1}{\sigma_0^2},\quad\frac{\mu_n}{\sigma_n^2}=\frac{n}{\sigma^2}\hat{\mu_n}+\frac{\mu_0}{\sigma_0^2},\quad \hat{\mu_n}=\frac{1}{n}\sum\limits_{i=1}^{n}x_i\end{aligned}$
	
	     > $\Huge\begin{aligned}\mu_n=\frac{n\sigma_0^2}{n\sigma_0^2+\sigma^2}\hat{\mu_n}+\frac{\sigma^2}{n\sigma_0^2+\sigma^2}\mu_0, \quad\sigma_n^2=\frac{\sigma_0^2\sigma^2}{n\sigma_0^2+\sigma^2}\end{aligned}$
- 现在，我们希望获得后验数据分布。
	- $\Huge\begin{aligned}p(x|D)&=\int_\mu p(x|\mu)p(\mu|D)d\mu \\&= \int_\mu\frac{1}{\sqrt{2\pi}\sigma}\exp\Big(-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}\frac{1}{\sqrt{2\pi}\sigma_n}\exp\Big(-\frac{1}{2}\frac{(x-\mu_n)^2}{\sigma_n^2}\Big)\Big)d\mu\\ &=\frac{1}{2\pi\sigma\sigma_n}\exp\Bigg(-\frac{1}{2}\frac{(x-\mu_n)^2}{\sigma^2+\sigma_n^2}\Bigg)f(\sigma,\sigma_n)\\ & f(\sigma,\sigma_n)=\int_\mu\frac{1}{\sqrt{2\pi}\sigma}\exp\Bigg(-\frac{1}{2}\frac{\sigma^2+\sigma_n^2}{\sigma^2\sigma_n^2}\Big(\mu-\frac{\sigma_n^2x+\sigma^2\mu_n}{\sigma^2+\sigma_n^2}\Big)^2\Bigg)\end{aligned}$
### 正态分布贝叶斯估计总结
- 贝叶斯估计与最大似然估计
	- 一维情况下，$x\sim N(\mu,\sigma), \quad p(\mu)\sim N(\mu_0,\sigma_0^2), \quad |\quad\mu 未知，\sigma,\sigma_0,\mu_0已知$
	- $p(\mu|D)\sim N(\mu_n,\sigma_n^2)$
	- 贝叶斯估计： $\Huge p(x|D)\sim N(\mu_n,\sigma^2+\sigma_n^2)$
	- 最大似然估计：$\Huge p(x|D)\sim N(\hat{\mu_n},\sigma^2)$
		- $\Huge\begin{aligned}\mu_n=\frac{n\sigma_0^2}{n\sigma_0^2+\sigma^2}\hat{\mu_n}+\frac{\sigma^2}{n\sigma_0^2+\sigma^2}\mu_0, \quad\sigma_n^2=\frac{\sigma_0^2\sigma^2}{n\sigma_0^2+\sigma^2}\end{aligned}$
		- $\Huge\hat{\mu_n}=\frac{1}{n}\sum\limits_{i=1}^nx_i$
	- <font color="#ffafa0">$\Large\begin{aligned}&当p(x|\mu)\sim N(\mu,\sigma^2),\quad p(\mu|D)\sim N(\mu_n,\sigma_n^2)\\&p(x|D)=\int_\mu p(x|\mu)p(\mu|D)d\mu\sim N(\mu_n,\sigma^2+\sigma_n^2) \end{aligned}$</font>
- 多元情形下（高维情形）：
	- ![](../photo/Pasted%20image%2020241005155715.png)![](../photo/Pasted%20image%2020241005155749.png)

### 贝叶斯学习总结

$\Huge p(\theta),p(x|\theta)\longrightarrow p(\theta|D)\longrightarrow p(x|D)$

$\Huge先验知识 \longrightarrow参数的后验分布 \longrightarrow 数据的后验分布$

- 遇到的困难
	- 除了一些特殊的分布(共轭分布)之外，对于一般的清醒，积分很难计算$p(x|D)=\int_\theta p(x|\theta)p(\theta|D)d\theta$
	- 参数先验$p(\theta)怎么选取？对结果有何影响？$
	- 给定D，我们真的能通过$p(x|D)$将$p(x)$估计的很好吗？或者说，随着D中的样本增多，$p(x|D)$收敛于$p(x)$吗。
### <font color="#ffa000">贝叶斯学习中的迭代计算公式</font>
	 
 $\large\begin{aligned}D^n&=\{x_1,x_2,\dots,x_n\},由于样本是独立选样的，则：\\p(D^n|\theta)&=p(x_n|\theta)p(D^{n-1}|\theta)=\dots\end{aligned}$
- 有以下迭代公式：
- 用前n-1个数据获得的参数分布来对其加权 ？
- $\begin{aligned}p(\theta|D^n)&=\frac{p(D^n|\theta)p(\theta)}{\int p(D^n|\theta)p(\theta)d\theta}=\frac{p(x_n|\theta)p(D^{n-1}|\theta)p(\theta)}{\int p(x_n|\theta)p(D^{n-1}|\theta)p(\theta)d\theta}\\ &=\frac{p(x_n|\theta)}{\int p(x_n|\theta)\frac{p(D^{n-1}|\theta)p(\theta)}{\int p(D^{n-1}|\theta)p(\theta)d\theta}d\theta} \cdot \frac{p(D^{n-1}|\theta)p(\theta)}{\int p(D^{n-1}|\theta)p(\theta)d\theta} \\ &=\frac{p(x_n|\theta)p(\theta|D^{n-1})}{\int p(x_n|\theta)p(\theta|D^n-1)d\theta}\end{aligned}$
- **参数迭代学习方法**
	- 为统一表示，记参数先验分布$\,p(\theta)\,$为$\,p(\theta|D^0)\,$表示没有样本情形下的参数概率密度估计。
	- 记$\,D^n=\{x_1,x_2,\dots,x_n\},随着样本你的增加，可以得到一系列对参数的概率密度函数的估计：$
		- $p(\theta),p(\theta|x_1),p(\theta|x_1,x_2),p(\theta|x_1,x_2,x_3),\cdots,p(\theta|x_1,x_2,\dots,x_n),\cdots$
	- 一般来说随着样本的数目增加，上述序列函数逐渐尖锐（方差变小），逐步趋向于以$\theta$的真值为中心的一个尖峰。
		- 当样本无穷多时，此时将收敛于一个脉冲函数（参数真值）。